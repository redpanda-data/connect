name: twitter_search
type: input
status: experimental
categories: [ Services, Social ]
summary: Consumes tweets matching a given search using the Twitter recent search V2 API.
description: |
  Continuously polls the https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent[Twitter recent search V2 API^] for tweets that match a given search query.

  Each tweet received is emitted as a JSON object message, with a field `id` and `text` by default. Extra fields https://developer.twitter.com/en/docs/twitter-api/fields[can be obtained from the search API^] when listed with the `tweet_fields` field.

  In order to paginate requests that are made the ID of the latest received tweet is stored in a xref:components:caches/about.adoc[cache resource], which is then used by subsequent requests to ensure only tweets after it are consumed. It is recommended that the cache you use is persistent so that Redpanda Connect can resume searches at the correct place on a restart.

  Authentication is done using OAuth 2.0 credentials which can be generated within the https://developer.twitter.com[Twitter developer portal^].

fields:
  - name: query
    description: A search expression to use.
    type: string

  - name: tweet_fields
    description: An optional list of additional fields to obtain for each tweet, by default only the fields `id` and `text` are returned. For more info refer to the https://developer.twitter.com/en/docs/twitter-api/fields[twitter API docs^].
    type: string
    kind: list
    default: []

  - name: poll_period
    description: The length of time (as a duration string) to wait between each search request. This field can be set empty, in which case requests are made at the limit set by the rate limit. This field also supports cron expressions.
    type: string
    default: "1m"

  - name: backfill_period
    description: A duration string indicating the maximum age of tweets to acquire when starting a search.
    type: string
    default: "5m"

  - name: cache
    description: A cache resource to use for request pagination.
    type: string

  - name: cache_key
    description: The key identifier used when storing the ID of the last tweet received.
    type: string
    default: last_tweet_id
    advanced: true

  - name: rate_limit
    description: An optional rate limit resource to restrict API requests with.
    type: string
    default: ""
    advanced: true

  - name: api_key
    description: An API key for OAuth 2.0 authentication. It is recommended that you populate this field using xref:configuration:interpolation.adoc[environment variables].
    type: string

  - name: api_secret
    description: An API secret for OAuth 2.0 authentication. It is recommended that you populate this field using xref:configuration:interpolation.adoc[environment variables].
    type: string

mapping: |
  #!blobl
  let _ = if this.poll_period == "" && this.rate_limit == "" {
    throw("either a poll_period, a rate_limit, or both must be specified")
  }

  let backfill_seconds = this.backfill_period.parse_duration() / 1000000000

  let query = "?max_results=100&query=" + this.query.escape_url_query()

  let query = if this.tweet_fields.length() > 0 {
    $query + "&tweet.fields=" + this.tweet_fields.join(",").escape_url_query()
  }

  let url = "https://api.twitter.com/2/tweets/search/recent" + $query

  root.generate.interval = this.poll_period
  root.generate.mapping = "root = \"\""

  root.processors = []

  root.processors."-".cache = {
    "resource": this.cache,
    "operator": "get",
    "key": this.cache_key,
  }

  root.processors."-".catch = [] # Don't care if the cache is empty

  root.processors."-".bloblang = """let pagination_params = if content().length() == 0 {
    "&start_time="+(timestamp_unix()-%v).format_timestamp("2006-01-02T15:04:05Z","UTC").escape_url_query()
  } else {
    "&since_id="+content().string()
  }
  meta tweet_search_url = "%v" + $pagination_params
  root = ""
  """.format($backfill_seconds, $url)

  root.processors."-".http = {
    "url": """${! meta("tweet_search_url") }""",
    "verb": "GET",
    "rate_limit": this.rate_limit,
    "oauth2": {
      "enabled": true,
      "token_url": "https://api.twitter.com/oauth2/token",
      "client_key": this.api_key,
      "client_secret": this.api_secret,
    },
  }

  root.processors."-".switch = [
    {
      "check": """root = error().or("").contains("'since_id' must be a tweet id created after")""",
      "processors": [
        {
          "cache": {
            "resource": this.cache,
            "operator": "set",
            "key": this.cache_key,
            "value": "",
          },
        },
        { "bloblang": "root = deleted()" },
      ],
    },
  ]

  root.processors."-".bloblang = "root = if (this.data | []).length() > 0 { this.data } else { deleted() }"

  root.processors."-".unarchive = {
    "format": "json_array"
  }

  root.processors."-".cache = {
    "resource": this.cache,
    "operator": "set",
    "key": this.cache_key,
    "value": """${! json("id") }""",
  }

  root.processors."-".catch = [
    {
      "log": {
        "level": "ERROR",
        "message": "Failed to write latest tweet ID to cache: ${! error() }",
      }
    }
  ]

  root.processors."-".split = {}

metrics_mapping: |
  #!blobl
  meta label = $label | ""
  let mpath = meta("path").or("")

  let name_path = if $mpath.has_suffix("processors.7") && this == "processor_received" {
    {
      "name": "input_received",
      "path": $mpath.re_replace(".processors.7$", ""),
    }
  } else if $mpath.has_suffix("processors.3") && this == "processor_error" {
    {
      "name": "input_error",
      "path": $mpath.re_replace(".processors.3$", ""),
    }
  }

  meta path = $name_path.path | deleted()
  root = $name_path.name | deleted()

tests:
  - name: Basic fields
    config:
      query: benthos.dev
      cache: foocache
      rate_limit: foolimit
      api_key: fookey
      api_secret: foosecret

    expected:
      generate:
        interval: '1m'
        mapping: root = ""
      processors:
        - cache:
            resource: foocache
            operator: get
            key: last_tweet_id

        - catch: []

        - bloblang: |
            let pagination_params = if content().length() == 0 {
              "&start_time="+(timestamp_unix()-300).format_timestamp("2006-01-02T15:04:05Z","UTC").escape_url_query()
            } else {
              "&since_id="+content().string()
            }
            meta tweet_search_url = "https://api.twitter.com/2/tweets/search/recent?max_results=100&query=benthos.dev" + $pagination_params
            root = ""

        - http:
            url: ${! meta("tweet_search_url") }
            verb: GET
            rate_limit: foolimit
            oauth2:
              enabled: true
              token_url: https://api.twitter.com/oauth2/token
              client_key: fookey
              client_secret: foosecret

        - switch:
          - check: 'root = error().or("").contains("''since_id'' must be a tweet id created after")'
            processors:
              - cache:
                  resource: foocache
                  operator: set
                  key: last_tweet_id
                  value: ""
              - bloblang: root = deleted()

        - bloblang: root = if (this.data | []).length() > 0 { this.data } else { deleted() }

        - unarchive:
            format: json_array

        - cache:
            resource: foocache
            operator: set
            key: last_tweet_id
            value: ${! json("id") }

        - catch:
          - log:
              level: ERROR
              message: "Failed to write latest tweet ID to cache: ${! error() }"

        - split: {}

  - name: With tweet fields set
    config:
      query: hello world
      cache: barcache
      backfill_period: 600s
      api_key: barkey
      api_secret: barsecret
      tweet_fields:
        - created_at
        - public_metrics

    expected:
      generate:
        interval: '1m'
        mapping: root = ""
      processors:
        - cache:
            resource: barcache
            operator: get
            key: last_tweet_id

        - catch: []

        - bloblang: |
            let pagination_params = if content().length() == 0 {
              "&start_time="+(timestamp_unix()-600).format_timestamp("2006-01-02T15:04:05Z","UTC").escape_url_query()
            } else {
              "&since_id="+content().string()
            }
            meta tweet_search_url = "https://api.twitter.com/2/tweets/search/recent?max_results=100&query=hello+world&tweet.fields=created_at%2Cpublic_metrics" + $pagination_params
            root = ""

        - http:
            url: ${! meta("tweet_search_url") }
            verb: GET
            rate_limit: ""
            oauth2:
              enabled: true
              token_url: https://api.twitter.com/oauth2/token
              client_key: barkey
              client_secret: barsecret

        - switch:
          - check: 'root = error().or("").contains("''since_id'' must be a tweet id created after")'
            processors:
              - cache:
                  resource: barcache
                  operator: set
                  key: last_tweet_id
                  value: ""
              - bloblang: root = deleted()

        - bloblang: root = if (this.data | []).length() > 0 { this.data } else { deleted() }

        - unarchive:
            format: json_array

        - cache:
            resource: barcache
            operator: set
            key: last_tweet_id
            value: ${! json("id") }

        - catch:
          - log:
              level: ERROR
              message: "Failed to write latest tweet ID to cache: ${! error() }"

        - split: {}
